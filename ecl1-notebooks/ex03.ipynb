{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# ECL I: Exercises 3: Training a simple tnt-like POS tagger\n",
    "In the lecture we heard (criteria for a good tagger): adjustability, reusability \n",
    "What exactly does that mean? A statistical tagger as the TnT tagger can be trained for every language and tagset. The only thing necessary is a corpus tagged with POS tags. Here we demonstrate two different implementations of the tnt tagger:\n",
    " - the [NLTK tnt reimplementation](https://www.nltk.org/_modules/nltk/tag/tnt.html) where you can look at the Python source code if your are interested. Training and tagging is wrapped with a [small wrapper script](ex03/tagger.py) that you can look at. This tagger is pretty slow during tagging. The good thing is that you can inspect the python [code](https://www.nltk.org/_modules/nltk/tag/tnt.html).\n",
    "\n",
    "-  the [hunpos tagger](https://github.com/mivoq/hunpos) builds a model file during training with a separate training program. This model file is then used by the tagger program and applied in a very efficient way.  For [our UD pipeline web demo](https://pub.cl.uzh.ch/users/siclemat/lehre/ecl1/ud-de-hunpos-maltparser/html/), we use the  hunpos tagger because it is super fast and supports unknown word guessing. \n",
    "\n",
    "\n",
    "Explanation: All lines start with a ! are UNIX-Shell-commands executed via this Notebook.\n",
    "You can always execute them without the ! directly in a terminal.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (0) Go to the right working directory\n",
    "Be sure to start with the process in the same directory as your corpus, the python program tagger.py as well as the evaluation script tag-eval.perl.\n",
    "To navigate your system use pwd (print working directory), cd (change directory) as well as ls (to see everything that is contained in the current directory).\n",
    "In a Notebook you can use the magic command %cd to change the current directory for all succeeding commands. We need to be in the ex03 directory after the following command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd ex03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls -l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  (1) 9/10 of the corpus will be our training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!head -n 277270 ud-de-v2.tts > training.tts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (1a) Look at training data\n",
    "Which tokens with the string \"bestimmt\" do have which UPOS tags?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!grep -C 3 bestimmt training.tts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## (2) 1/10 of our corpus will be our test data\n",
    " Copy the last 30807 lines into `test.tts`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! tail -n 30807 ud-de-v2.tts > test.tts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (3) create an evaluation corpus by removing the tags from our test corpus\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! cut -f 1 test.tts > test.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (4) Train a model with hunpos training tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! hunpos-train training.mod < training.tts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (5) Tag the test set with the hunpos tagger and the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! hunpos-tag training.mod < test.txt > result.tts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (4b/5b)  Training and tagging with NLTK tnt tagger:\n",
    "Train the tagger with training.tts. Tag the evaluation file and write the results in result.tts (this can take a few minutes ... be patient). Some status information will appear on standard error.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! python3 tagger.py training.tts < test.txt > result-nltk.tts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (6) Evaluation of hunpos tagger output\n",
    "Evaluate the *hunpos tagger result* with a nice confusion matrix by comparing our tagger output `result.tts` with the test corpus `test.tts`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! perl tag-eval.perl -k test.tts -e result.tts "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (6b) Evaluation of NLTK tagger output\n",
    "Evaluate the NLTK tnt tagger:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! tag-eval.perl -e results-nltk.tts -k test.tts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our simple NLTK-based POS Tagger does not guess unknown words... See yourself..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!grep -C 3 Unk result-nltk.tts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (7) Testing with your own tokenized input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! echo \"Dies ist ein Satz !\" | tr \" \" \"\\n\" | hunpos-tag training.mod "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Control question\n",
    "\n",
    "What happens if you train over the whole corpus and evaluate afterwards? (Just substitute \"training.tts\" in the training and tagging command with the whole corpus \"ud-de-v2.tts\")\n",
    "\n",
    "Supplement: How to compute the length of your training and test corpus automatically according to your split proportions? Note: This simple method can cut in the middle of a sentence...\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "export corpuslen=$(wc -l <ud-de-v2.tts )\n",
    "export testlen=$(($corpuslen / 10 ))\n",
    "export trainlen=$(($corpuslen - $testlen))\n",
    "echo Corpus lines $corpuslen test lines $testlen training lines $trainlen\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
