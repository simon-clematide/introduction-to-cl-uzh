{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# ECL I: Exercises 3: Training a simple tnt-like tagger\n",
    "In the lecture we heard (criteria for a good tagger): adjustability, reusability \n",
    "What exactly does that mean? A tagger like e.g. the TnT-Tagger can be trained for every language and tagset. The only thing necessary is a corpus, tagged with POS-Tags.\n",
    "\n",
    "Explanation: All lines start with a ! are UNIX-Shell-commands executed via this Notebook.\n",
    "You can always execute them without the ! directly in a terminal.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (1) Go to the right working directory\n",
    "Be sure to start with the process in the same directory as your corpus, the python program tagger.py as well as the evaluation script tag-eval.perl.\n",
    "To navigate your system use pwd (print working directory), cd (change directory) as well as ls (to see everything that is contained in the current directory).\n",
    "In a Notebook you can use the magic command %cd to change the current directory for all succeeding commands. We need to be in the ex03 directory after the following command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd ex03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls -l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  (2) 9/10 of the corpus will be our training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!head -n 277313 ud-de-v2.tts > training.tts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (3) Look at training data\n",
    "Which tokens with the string \"bestimmt\" do have which UPOS tags?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!grep -C 3 bestimmt training.tts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## (4) 1/10 of our corpus will be our test data\n",
    " Copy the last 30812 lines into `test.tts`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! tail -n 30812 ud-de-v2.tts > test.tts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (5) create an evaluation corpus by removing the tags from our test corpus\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! cut -f 1 test.tts > test.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (6)  Training and tagging:\n",
    "Train the tagger with training.tts. Tag the evaluation file and write the results in result.tts (this can take a few minutes ... be patient). Some status information will appear on standard error.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! python3 tagger.py training.tts < test.txt > result.tts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (7) Evaluation\n",
    "Evaluate the result with a nice confusion matrix by comparing our tagger output `result.tts` with the test corpus `test.tts`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! perl tag-eval.perl -k test.tts -e result.tts "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our simple NLTK-based POS Tagger does not guess unknown words... See yourself..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!grep -C 3 Unk result.tts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Control question\n",
    "\n",
    "What happens if you train over the whole corpus and evaluate afterwards? (Just substitute \"training.tts\" in the training and tagging command with the whole corpus \"ud-de-v2.tts\")\n",
    "\n",
    "Supplement: How to compute the length of your training and test corpus automatically? This might just cut in the middle of a sentence...\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "export corpuslen=$(wc -l <ud-de-v2.tts )\n",
    "export testlen=$(($corpuslen / 10 ))\n",
    "export trainlen=$(($corpuslen - $testlen))\n",
    "echo Corpus lines $corpuslen test lines $testlen training lines $trainlen\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using the hunpos tagger\n",
    "Our tnt-like tagger is pretty slow. The good thing is that you can inspect the python [code](https://www.nltk.org/_modules/nltk/tag/tnt.html). For [our UD pipeline web demo](https://pub.cl.uzh.ch/users/siclemat/lehre/ecl1/ud-de-hunpos-maltparser/html/), we use the tnt reimplementation hunpos which is a lot faster and supports unknown word guessing. \n",
    "\n",
    "Training with hunpos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! hunpos-train training.mod < training.tts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tagging with hunpos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! hunpos-tag training.mod < test.txt > results.tts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluating the result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! tag-eval.perl -e results.tts -k test.tts"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
