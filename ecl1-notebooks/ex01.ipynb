{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# ECL I Exercise 1 Task 4: experiments with existing tokenizers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Using cutter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center"
   },
   "source": [
    "Execute the following two cells (Shift+Return) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mary-Louise kindly went over to Ms. O’Connor’s house and asked her for some soy-milk because we had run out of it.\r\n",
      "“Like… seriously? They wanted me to pay a full £18 for some tea and scones!” – “You’re right, that really is expensive!”\r\n",
      "don’t @ me for using too many hashtags, I just love ‘em so much #doitforthegram #hashtagsforlife\r\n",
      "I wish someone had told me that it’ll be only 8°C outside today, I would’ve worn thicker clothes.\r\n",
      "The last train he can take leaves at 17:30 pm… I hope he makes it.\r\n",
      "haven’t even put on my socks & shoes and 5 ppl have already tried to call me\r\n"
     ]
    }
   ],
   "source": [
    "! cat ex01/task4_text_en.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "! cat ex01/task4_text_de.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copy the texts from above into the input form of the cutter web demo:\n",
    "https://pub.cl.uzh.ch/projects/sparcling/cutter/current/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Moses tokenizer\n",
    "The moses tokenizer is another multilingual tokenizer, known from the statistical Machine Translation system [moses](https://github.com/moses-smt/mosesdecoder/blob/master/scripts/tokenizer/tokenizer.perl) and written in the programming language PERL (once a very popular language in the NLP community). It does not produce verticalized text, but separates tokens by spaces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Liebes Tagebuch ! Am 14 . September hat das Herbstsemester 2020 begonnen . Corona-bedingt ist alles etwas anders : Anstatt Mensa-Essen und Präsenzveranstaltungen warten online-Vorlesungen , Zoom-Tutorate etc. auf mich . Vor allem die ECL I Vorlesung gefällt mir und ich kann es kaum erwarten , mehr über maschinelle Sprachverarbeitung zu lernen . Ich bin u.a. gespannt auf die Tutorate , die ab der zweiten Woche jeden Freitag um 12 Uhr 15 stattfinden . Die Kennen + Lern-Tage wurden leider abgesagt ... Umso mehr freue ich mich darauf , meine Kommiliton / -innen beim gemeinsamen Lernen besser kennen zu lernen ! : - )\r\n"
     ]
    }
   ],
   "source": [
    "!perl ex01/tokenizer.perl  -q -l de < ex01/task4_text_de.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!perl ex01/tokenizer.perl -no-escape -q -l en < ex01/task4_text_en.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Further information\n",
    "Note that the moses tokenizer can be tuned to your domain by specifying a file with patterns. Text pieces matched by these patterns are never split inside."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mary-Louise kindly went over to Ms. O ’ Connor ’ s house and asked her for some soy-milk because we had run out of it .\r\n",
      "“ Like … seriously ? They wanted me to pay a full £ 18 for some tea and scones ! ” – “ You ’ re right , that really is expensive ! ”\r\n",
      "don ’ t @ me for using too many hashtags , I just love ‘ em so much #doitforthegram #hashtagsforlife\r\n",
      "I wish someone had told me that it ’ ll be only 8 ° C outside today , I would ’ ve worn thicker clothes .\r\n",
      "The last train he can take leaves at 17 : 30 pm … I hope he makes it .\r\n",
      "haven ’ t even put on my socks & shoes and 5 ppl have already tried to call me\r\n"
     ]
    }
   ],
   "source": [
    "!perl ex01/tokenizer.perl -protected ex01/protected-en.txt -no-escape -q -l en < ex01/task4_text_en.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
