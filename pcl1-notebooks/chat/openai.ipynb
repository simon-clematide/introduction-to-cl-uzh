{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d6e64179-1ce2-4b73-8fd1-b22f2a7328a7",
   "metadata": {},
   "source": [
    "# Demonstrating Open AI's Chat Completion API\n",
    "What you will learn:\n",
    "  - How to format prompts\n",
    "  - How to use system and user role\n",
    "  - How to enforce JSON output\n",
    "  - Learn some nice practices how to specify the output format"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96d4bc4d-4df1-4052-8557-47ecc2935fb4",
   "metadata": {},
   "source": [
    "## Installation and setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "670a4489-2b96-4380-b4a9-28550d4d7089",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef3771c2-6b40-4fec-a45c-2ad8d9633dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# short cut\n",
    "API_KEY = \"YOUR_API_KEY_HERE\" # don't publish your API keys (they are connected to a credit card, but limited to 1$)\n",
    "\n",
    "# A better way to protect it, is to set it in the environment\n",
    "# import os\n",
    "# API_KEY = os.getenv('MYOPENAIKEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebe56c48-d2a0-4f8e-90ad-7b7793a15d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "# Initialize the OpenAI client\n",
    "client = OpenAI(api_key=API_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79ca9e07-c770-4e19-b321-0169546b7a0b",
   "metadata": {},
   "source": [
    "## Defining a chat completion function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "275e60fe-1405-4953-a918-62e73faddd99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_chat_turn(system_message: str, user_prompt: str, response_format:str = \"text\", model:str=\"gpt-4o-mini\") -> str:\n",
    "    \"\"\"\n",
    "    Sends a chat turn to the OpenAI model and returns the assistant's response.\n",
    "    \n",
    "    Args:\n",
    "        system_message (str): The system message providing context or instructions for the assistant.\n",
    "        user_prompt (str): The user's input prompt.\n",
    "        response_format (str): \"text\" or \"json_object\"\n",
    "    \n",
    "    Returns:\n",
    "        str: The assistant's response.\n",
    "    \"\"\"\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,  # your PCL 1 API keys can use gpt-4o (15 times more expensive) or gpt-4o-mini\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_message},\n",
    "            {\"role\": \"user\", \"content\": user_prompt}\n",
    "        ],\n",
    "        temperature=1,\n",
    "        max_tokens=1000,\n",
    "        top_p=1,\n",
    "        response_format={\n",
    "        \"type\": response_format\n",
    "    },\n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be6ef625-3ae3-40ea-a63d-eb1c0fa874cf",
   "metadata": {},
   "source": [
    "### Testing the function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "902a9e42-3430-4ffa-8d35-218c0e3119f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = \"You are a helpful assistant.\"\n",
    "user_prompt = \"Explain the benefits of learning Python.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d767ce7d-1918-423f-9290-2337fd6ba9da",
   "metadata": {},
   "outputs": [],
   "source": [
    "assistant_response = run_chat_turn(system_message, user_prompt)\n",
    "print(assistant_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00cc8f24-976c-4a5c-9dfa-07bf254dec01",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = \"You are an AI that lies to people in absurd ways to make them think by themselves!\"\n",
    "user_prompt = \"Explain the benefits of learning Python.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26df9133-91c8-425a-a6e0-fd5ac0412f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "assistant_response = run_chat_turn(system_message, user_prompt)\n",
    "print(assistant_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3dfa5b1-8ee6-4a62-b9d9-3c47f80e8847",
   "metadata": {},
   "source": [
    "## A real relation mining use case\n",
    " - Let's solve a more relevant problem by machine reading and machine generation of structured output\n",
    " - Can LLMs solve a specific relation mining problem?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7130b49-d64f-4c8e-a3f2-31a4b73f53cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = \"You are an expert in mountaineering.\"\n",
    "user_prompt = \"\"\"Here is a paragraph from the OCR-ized British Alpine Magazine from 1969.\n",
    "\n",
    "PARAGRAPH:\n",
    "\"The ranks ot ' famous ' climbers can never be closed .\n",
    "Hut what does tame mean to climbing ?\n",
    "The true climber seeks his fulfilment in the limitations set to him personally by the forces of Nature .\n",
    "Whether this fulfilment is found in walking amongst mountains or in conquering extreme routes , it is all the same in the end .\n",
    "With luck , climbing will never become a competitive ' Sport ' , nor appear in the Olympic Games , \n",
    "although already two Olympic Gold Medals have been bestowed to climbers one in iy}2 to the brothers Schmid \n",
    "for their first ascent ot the Matterhorn North face and another in 10,^6 to Günther Oskar Dyhrenfurth for his success in \n",
    "his great Himalayan undertakings .\n",
    "\"\n",
    "\n",
    "\n",
    "An entity recognition system recognized the following mountain:\n",
    " - Matterhorn\n",
    "\n",
    "\n",
    "The entity recognition system also recognized the following persons:\n",
    " - Günther Oskar Dyrthenfurth\n",
    "\n",
    "Now, analyze and report for each person in a JSON data structure of the following format: \n",
    "    \n",
    "    { \n",
    "      \"mountain\": MOUNTAIN, \n",
    "      \"relations\":[ \n",
    "        {\"person_name\": PERSON_NAME1, \"is_mountaineer\": true/false/null , \"climbed_mountain\": true/false/null},\n",
    "        {\"person_name\": PERSON_NAME2, \"is_mountaineer\": true/false/null , \"climbed_mountain\": true/false/null},\n",
    "        ...\n",
    "        ] \n",
    "    }\n",
    "\n",
    "Use your background knowledge and the paragraph to decide whether the recognized person is a mountaineer (true) or not (false). \n",
    "In case you don't know, set the value to null.\n",
    "\n",
    "For each mountaineer (person with is_mountaineer: true), decide whether there is textual evidence in the paragraph \n",
    "that they actually climbed this mountain. Use the value null if the evidence in the paragraph is inconclusive.\n",
    "\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e15ecd2-dfbd-4fcb-a50a-62869ec91199",
   "metadata": {},
   "outputs": [],
   "source": [
    "assistant_response = run_chat_turn(system_message, user_prompt,response_format=\"json_object\",model=\"gpt-4o\")\n",
    "print(assistant_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb5fa4db-9d42-498f-bcf8-75002494d02a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# structured data from AI\n",
    "import json\n",
    "output = json.loads(assistant_response)\n",
    "mountain = output[\"mountain\"]\n",
    "for person in output[\"relations\"]:\n",
    "    print(person[\"person_name\"], person[\"is_mountaineer\"])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f37946d7-7fba-4232-9176-4eb5a64b446c",
   "metadata": {},
   "source": [
    "Look at the original article: http://www.alpinejournal.org.uk/Contents/Contents_1969_files/AJ%201969%2047-57%20Heckmair%20Climbers.pdf"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
