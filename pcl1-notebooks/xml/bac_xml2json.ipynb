{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XML to JSONL processing\n",
    "Turn annotated corpus file in XML format into task-specific JSONL format\n",
    "  - Each XML paragraph (`<div>`) is one line in JSONL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input file from British Alpine Club"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! head -n 40 BAC_1969_a0_en.xml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Traverse XML file and aggregate words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "import json\n",
    "\n",
    "\n",
    "# Parse the XML file\n",
    "def extract_sentences_to_jsonl(xml_file, jsonl_file):\n",
    "    tree = ET.parse(xml_file)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    with open(jsonl_file, 'w', encoding='utf-8') as jsonl:\n",
    "        \n",
    "        for paragraph in root.iter(\"div\"):\n",
    "            # Extract text content from each 'w' within 'div'\n",
    "            words = [w.text for w in paragraph.iter(\"w\") if w.text.strip()]\n",
    "            text = \" \".join(words).strip()\n",
    "            \n",
    "            jsonl.write(json.dumps({\"text\": text},ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "    print(f\"Paragraphs extracted and saved to {jsonl_file}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and parse the XML file\n",
    "xml_file = 'BAC_1969_a0_en.xml'      # Path to your XML file\n",
    "jsonl_file = 'BAC_1969_a0_en_paras.jsonl'      # Path to output JSONL file\n",
    "\n",
    "\n",
    "# Run the function\n",
    "extract_sentences_to_jsonl(xml_file, jsonl_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! cat  BAC_1969_a0_en_paras.jsonl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can you modify the code that the id of the first and last sentence is used as the id of the paragraph? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Can we convert this JSONL data into an Excel file?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install pandas openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def extract_sentences_to_excel(xml_file, excel_file):\n",
    "    tree = ET.parse(xml_file)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    data = []\n",
    "    for paragraph in root.iter(\"div\"):\n",
    "        # Extract text content from each 'w' within 'div'\n",
    "        words = [w.text for w in paragraph.iter(\"w\") if w.text and w.text.strip()]\n",
    "        text = \" \".join(words).strip()\n",
    "\n",
    "        if text:  # Add only non-empty paragraphs\n",
    "            data.append({\"text\": text})\n",
    "\n",
    "    # Convert data to a DataFrame and write to Excel\n",
    "    df = pd.DataFrame(data)\n",
    "    df.to_excel(excel_file, index=False)\n",
    "    print(f\"Paragraphs extracted and saved to {excel_file}\")\n",
    "\n",
    "\n",
    "excel_file = 'BAC_1969_a0_en_paras.xlsx'      # Path to output JSONL file\n",
    "extract_sentences_to_excel(xml_file, excel_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read NER file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! head -n 30 BAC_1969_a0_en-ner.xml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "import json\n",
    "\n",
    "# Load and parse the NER XML file\n",
    "ner_file = 'BAC_1969_a0_en-ner.xml'  # Path to your NER XML file\n",
    "jsonl_file = 'BAC_1969_a0_en-ner_mountain_occurrences.jsonl'  # Path to output JSONL file\n",
    "\n",
    "\n",
    "# Parse the XML file\n",
    "def extract_mountain_occurrences_to_jsonl(ner_file, jsonl_file):\n",
    "    tree = ET.parse(ner_file)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    # Dictionary to store mountain occurrences\n",
    "    mountain_to_sentence_ids = {}\n",
    "\n",
    "    # Iterate over all entities\n",
    "    for entity in root.iter(\"g\"):\n",
    "        if entity.get('type') != \"mountain\":\n",
    "            continue\n",
    "        mountain_id = entity.get('stid')\n",
    "        span = entity.get('span')\n",
    "\n",
    "        if mountain_id and span:\n",
    "            sentence_id = \"-\".join(span.split(\"-\")[:2])  # Extract sentence ID from span\n",
    "            if mountain_id not in mountain_to_sentence_ids:\n",
    "                mountain_to_sentence_ids[mountain_id] = []\n",
    "            mountain_to_sentence_ids[mountain_id].append(sentence_id)\n",
    "\n",
    "    # Write results to JSONL\n",
    "    with open(jsonl_file, 'w', encoding='utf-8') as jsonl:\n",
    "        for mountain_id, sentence_ids in mountain_to_sentence_ids.items():\n",
    "            jsonl.write(json.dumps({\"mountain_id\": mountain_id, \"sentence_ids\": sentence_ids}) + \"\\n\")\n",
    "\n",
    "    print(f\"Mountain occurrences extracted and saved to {jsonl_file}\")\n",
    "\n",
    "# Run the function\n",
    "extract_mountain_occurrences_to_jsonl(ner_file, jsonl_file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat BAC_1969_a0_en-ner_mountain_occurrences.jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
