{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2be71bbb",
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# spaCy: An modern NLP pipeline\n",
    "Learning goals:\n",
    " - Understand how a modern NLP pipeline works and what spacy models typically do\n",
    " - Understand the main data structures: Doc, Token, Vocab\n",
    " - Understand how cosine similarity between tokens, spans and documents can be computed\n",
    " - Understand how rule-based matching with a domain-specific search query language works \n",
    " - Understand how rule-based entity matching can be done\n",
    " - Understand the Matcher and DependencyMatcher class\n",
    " - Understand what (de)serialization is and how it applies to spaCy data structures\n",
    " - Get to know the displacy visualization\n",
    " \n",
    " See [spaCy 101](https://spacy.io/usage/spacy-101) for an introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0101e44",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05821fbd",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Only run this once (restart the kernel if the models are not loaded)\n",
    "! pip install spacy\n",
    "! python -m spacy download en_core_web_sm\n",
    "! python -m spacy download en_core_web_md # with word vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0528e204",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Loading pipeline models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e16630e",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy import displacy \n",
    "model = 'en_core_web_sm'\n",
    "model_md = 'en_core_web_md'\n",
    "nlp = spacy.load(model)\n",
    "nlp_md = spacy.load('en_core_web_md')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e95d8034",
   "metadata": {},
   "source": [
    "The nlp object is an instance of the class [Language](https://spacy.io/api/language)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb0c5382",
   "metadata": {},
   "outputs": [],
   "source": [
    "isinstance(nlp, spacy.Language)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efb3cc61",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Pipeline processing and dependency parsing visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c02a862",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "doc = nlp('Mr. Smith founded a healthcare company. He is the CEO of Health Inc.')\n",
    "displacy.render(doc, style='dep',jupyter=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ffc3aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displaying entities\n",
    "displacy.render(doc, style='ent',jupyter=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4db9fdae",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "What information is in the analysed document? A compact way  to look at the most relevant information is  the [JSON](https://www.youtube.com/watch?v=pTT7HMqDnJw) serialization. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "889f12a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc.to_json()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92e57730",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Start and end of segments: spaCy uses Python [slice](https://docs.python.org/3.11/library/functions.html#slice) object semantics!\n",
    "`text[start:end]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7e6825c",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "'Mr. Smith founded a healthcare company. He is the CEO of Health Inc.'[4:9]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d86a853",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "A spaCy [Token](https://spacy.io/api/token) contains all information that is token-related. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ef86ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(doc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71375e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at all (inherited) attribute of the first token...\n",
    "for attribute in dir(doc[0]):\n",
    "    print(attribute, getattr(doc[0],attribute))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d855eb9f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Iterating over a document is iterating over its tokens. Many attributes are numerical indexes into the nlp's vocabulary. The string value can typically be found by adding an underscore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a75eb22",
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in doc:\n",
    "    print(t.i,t.text, t.pos_, t.pos, t.tag, t.lemma_,t.head.i, t.is_sent_start)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f4c534c",
   "metadata": {},
   "source": [
    "The vocabulary object maps strings on integers and vice versa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "450f394a",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp.vocab.strings.as_string(96)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "475f3fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp.vocab.strings[96]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf35b250",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp.vocab.strings.as_int(\"PROPN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa87c634",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp.vocab.strings[\"PROPN\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c58f4399",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Noun Chunks\n",
    "The nlp pipeline computes noun chunks for your convenience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bbe9f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Noun phrases:\", [chunk.text for chunk in doc.noun_chunks])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff846781",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "## Word Vectors\n",
    "Visualization of word vectors for human eyeballing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5a4f01e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def plot_words(words:str, nlp):\n",
    "    doc = nlp(words)\n",
    "    vectors = [token.vector for token in doc][:3]\n",
    "    x = np.arange(len(vectors[0])) \n",
    "    \n",
    "    # Plotting the data\n",
    "    plt.figure(figsize=(20, 4))\n",
    "    \n",
    "    for i, vector in enumerate(vectors):\n",
    "        plt.plot(x, vector,  linewidth=2, label=f'Word {i+1}', color=['red', 'green', 'blue'][i])\n",
    "    \n",
    "    plt.title('Which line represents which word?')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd208761",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "plot_words(\"love hate\",nlp_md)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19ecc640",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Computing Vector-based Similarity\n",
    "The medium pipeline contains better semantic word vectors than the small pipeline. If you want to know more about how the cosine similarity is computed, see [this cosine-similarity notebook](cosine-similarity.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "125bd6ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "text3= (\"Chemical similarity (or molecular similarity) refers to the similarity of chemical elements, molecules or chemical compounds \"\n",
    "        \"with respect to either structural or functional qualities, i.e. the effect that the chemical compound has on reaction partners \"\n",
    "        \"in inorganic or biological settings. Biological effects and thus also similarity of effects are usually quantified using \"\n",
    "        \"the biological activity of a compound. In general terms, function can be related to the chemical activity of compounds (among others).\")\n",
    "doc3 = nlp_md(text3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a47e34c6",
   "metadata": {},
   "source": [
    "How similar is the word \"molecular\" to the word \"molecules\"?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23fd312f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(doc3[4],doc3[15])\n",
    "doc3[4].similarity(doc3[15])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dc7d75c",
   "metadata": {},
   "source": [
    "How similar is the word \"or\" to the word \"molecules\"?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78194bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(doc3[3],doc3[15])\n",
    "doc3[3].similarity(doc3[15])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8589669e",
   "metadata": {},
   "source": [
    "How similar is the word \"molecular\" to the overall document?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91996e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "help(doc3[3].similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c551f648",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc3[4], doc3[4].similarity(doc3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bac1c721",
   "metadata": {},
   "source": [
    "How similar is the word \"or\" to the overall document?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc0ef9c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc3[3], doc3[3].similarity(doc3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2da0abb",
   "metadata": {},
   "source": [
    "You can check whether a word has a word vector (is not OOV) or whether it is a vector computed on the fly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3f2b16f",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc3[17].is_oov,doc3[17].vector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2da462b4",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Comparing tokens\n",
    "Compute for each word its most similar other word in the text and print them in order of their similarity score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a8ed97",
   "metadata": {},
   "outputs": [],
   "source": [
    "most_similar = {}  # dictionary that maps each token to its most similar, including the similarity score\n",
    "for i in doc3:\n",
    "    for j in doc3:\n",
    "        if i.text != j.text and i.text < j.text:\n",
    "            similarity = i.similarity(j)\n",
    "            if i.text in most_similar:\n",
    "                if most_similar[i.text][1] > similarity:\n",
    "                        continue\n",
    "            most_similar[i.text] = (j.text, similarity)\n",
    "\n",
    "for (sim, w1, w2) in sorted(((sim, w1, w2) for (w1,(w2,sim)) in most_similar.items()), reverse=True):\n",
    "    print(w1, w2, f\"{sim:.2f}\")            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d8701b5",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Comparing tokens with documents\n",
    "Compute a ranking of the words that are most similar to the document vector (average of all words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce2a768",
   "metadata": {},
   "outputs": [],
   "source": [
    "most_similar = {}\n",
    "for i in doc3:\n",
    "    similarity = i.similarity(doc3)\n",
    "    if (i.text) in most_similar:\n",
    "        if most_similar[i.text] > similarity:\n",
    "            continue\n",
    "    most_similar[i.text] = similarity\n",
    "\n",
    "for (sim, w1) in sorted(((sim, w1) for (w1,sim) in most_similar.items()), reverse=True):\n",
    "    print(w1, f\"{sim:.3f}\") \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ad65dc6",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Matching using token patterns\n",
    "spaCy has a powerful token-based pattern matching engine that can use [any of the linguistic properties of tokens for searching and adding informations](https://spacy.io/usage/rule-based-matching#adding-patterns-attributes). See the online demo for [interactively creating matching patterns](https://explosion.ai/demos/matcher).\n",
    "\n",
    "Let's implement a simple matcher:\n",
    "The normal NER of this model does not include titles. We can write a token matcher to rectify the situation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e1d7db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "displacy.render(doc2, style='ent',jupyter=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b2d832d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.matcher import Matcher\n",
    "matcher = Matcher(nlp.vocab) # initialize the matcher with the current Vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "063f0ca2",
   "metadata": {},
   "source": [
    "A pattern is a list of dictionaries. Each dictionary specifies a token pattern that can include regex-like repetition information. An empty dictionary `{}` matches any token. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39634f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = [{\"LOWER\":\"mr.\"},{\"ENT_TYPE\":\"PERSON\", \"OP\":\"+\"}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56b3fd78",
   "metadata": {},
   "outputs": [],
   "source": [
    "matcher.add(\"TitledPERSON\",[pattern])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af4228f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "matches = matcher(doc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e96d720",
   "metadata": {},
   "outputs": [],
   "source": [
    "for match_id, start, end in matches:\n",
    "    string_id = nlp.vocab.strings[match_id]          # Get string representation\n",
    "    span = doc[start:end]                            # The matched span\n",
    "    print(match_id, string_id, start, end, span.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a05d1f5",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## EntityRuler: A Matcher for Adding Entities from Scratch\n",
    "Automatically adds matched spans to Doc.ents See [doc](https://spacy.io/api/entityruler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc1d38c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp2 = spacy.load(\"en_core_web_sm\")\n",
    "doc3 = nlp2('\"Ah, Lysara,\" Thalric had said, his voice as deep and mysterious.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d6a10d",
   "metadata": {},
   "outputs": [],
   "source": [
    "displacy.render(doc3, style='ent',jupyter=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c16513f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ruler = nlp2.add_pipe(\"entity_ruler\", config={\"overwrite_ents\":True}) \n",
    "patterns = [{\"label\": \"PERSON\", \"pattern\": \"Thalric\"}]  # Add more patterns here]\n",
    "ruler.add_patterns(patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ea8788",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc3 = nlp2('\"Ah, Lysara,\" Thalric had said, his voice as deep and mysterious.')\n",
    "displacy.render(doc3, style='ent',jupyter=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63909324",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Navigating the dependency structure\n",
    "Apart from following the head attribute of each token, there is more functionality for traversing the dependency relations.\n",
    "The [children](https://spacy.io/api/token#children) generator for immediatly dependent words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f1a78de",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc[2].children"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42766b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Head:\", doc[2])\n",
    "for c in doc[2].children:\n",
    "    print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62ac0f98",
   "metadata": {},
   "source": [
    "Navigating the dependency structure: enumerating the heads of a token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da5e1fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in doc[0].ancestors:\n",
    "    print(t, type(t))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8220a0a1",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Matching using Dependency Patterns\n",
    "We can match non-contiguous slices via dependency relations.\n",
    "See [usage guide](https://spacy.io/usage/rule-based-matching#dependencymatcher-patterns) for more information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b421878",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.matcher import DependencyMatcher\n",
    "dep_matcher = DependencyMatcher(nlp.vocab) # initialize the matcher with the current Vocab\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f49a14d5",
   "metadata": {},
   "source": [
    "Let's define a simple verb subject pattern!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "158ff99f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dep_pattern = [\n",
    "    {\n",
    "        \"RIGHT_ID\": \"anchor_founded\",      # Introduce ID for anchor token\n",
    "        \"RIGHT_ATTRS\": {\"ORTH\": \"founded\"} # Specify anchor token\n",
    "    },\n",
    "    {\n",
    "        \"LEFT_ID\": \"anchor_founded\",       # Refer to anchor token by its ID\n",
    "        \"REL_OP\": \">\",                     # Direct dependency\n",
    "        \"RIGHT_ID\": \"founded_subject\",     # Introduce ID for dependent subject \n",
    "        \"RIGHT_ATTRS\": {\"DEP\": \"nsubj\"},   # Specify subject token\n",
    "    } \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d731fd51",
   "metadata": {},
   "outputs": [],
   "source": [
    "dep_matcher.add(\"FOUNDED\", [dep_pattern])\n",
    "doc3 = nlp(\"Smith, an experienced CEO, has founded two AI startups.\")\n",
    "dep_matches = dep_matcher(doc3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f90c370f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dep_matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d96f32b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each token_id corresponds to one pattern dict\n",
    "match_id, token_ids = dep_matches[0]\n",
    "\n",
    "for i in range(len(token_ids)):\n",
    "    print(dep_pattern[i][\"RIGHT_ID\"] + \":\", doc3[token_ids[i]].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f24868",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc3 = nlp(\"Smith, an experienced CEO, has founded two AI startups. He also launched several other companies.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b2cf6a0",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Serialization to disk and reading from disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d41350b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc.to_disk('my_doc.spacy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12cc85ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.tokens import Doc\n",
    "from spacy.vocab import Vocab\n",
    "my_vocab = Vocab() # create empty vocabulary or use existing compatible one, e.g. `nlp.vocab`\n",
    "loaded_doc = Doc(my_vocab).from_disk('my_doc.spacy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90e3d1ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_doc.to_json()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9941d6ed",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Combining a list of docs\n",
    "If you want to combine several docs in one document, you can use the static method (a function that is directly called from the class) `from_docs()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e08d9ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc2 = nlp('Mr. Smith continues to work for the company for the next 10 years.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a38aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_docs = Doc(nlp.vocab).from_docs([doc,doc2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b80a1bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_docs.to_json()"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
