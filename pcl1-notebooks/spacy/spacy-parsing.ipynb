{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2be71bbb",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "# spaCy: An modern NLP pipeline\n",
    "Learning goals:\n",
    " - Understand how a modern NLP pipeline works and what spacy models typically do\n",
    " - Understand the main data structures: Doc, Token, Vocab\n",
    " - Understand how rule-based matching with a domain-specific search query language works \n",
    " - Understand the Matcher and DependencyMatcher class\n",
    " - Understand what (de)serialization is and how it applies to spaCy data structures\n",
    " - Get to know the displacy visualization\n",
    " \n",
    " See [spaCy 101](https://spacy.io/usage/spacy-101) for an introduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05821fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only run this once (and maybe restart the kernel)\n",
    "! pip install spacy\n",
    "! python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e16630e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy import displacy \n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e95d8034",
   "metadata": {},
   "source": [
    "The nlp object is an instance of the class [Language](https://spacy.io/api/language)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb0c5382",
   "metadata": {},
   "outputs": [],
   "source": [
    "isinstance(nlp, spacy.Language)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c02a862",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp('Mr. Smith founded a healthcare company. He is the CEO.')\n",
    "displacy.render(doc, style='dep',jupyter=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4db9fdae",
   "metadata": {},
   "source": [
    "What information is in the analysed document? A compact way  to look at the most relevant informoation is  the [JSON](https://www.youtube.com/watch?v=pTT7HMqDnJw) serialization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "889f12a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc.to_json()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d86a853",
   "metadata": {},
   "source": [
    "A spaCy [Token](https://spacy.io/api/token) contains all information that is token-related. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ef86ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(doc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71375e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for attribute in dir(doc[0]):\n",
    "    print(attribute, getattr(doc[0],attribute))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d855eb9f",
   "metadata": {},
   "source": [
    "Iterating over a document is iterating over its tokens. Many attributes are numerical indexes into the nlp's vocabulary. The string value can typically be found by adding an underscore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a75eb22",
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in doc:\n",
    "    print(t.i,t.text, t.pos_, t.pos, t.tag, t.lemma_,t.head.i, t.is_sent_start)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f4c534c",
   "metadata": {},
   "source": [
    "The vocabulary object maps strings on integers and vice versa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "450f394a",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp.vocab.strings.as_string(96)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "475f3fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp.vocab.strings[96]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf35b250",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp.vocab.strings.as_int(\"PROPN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa87c634",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp.vocab.strings[\"PROPN\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b2cf6a0",
   "metadata": {},
   "source": [
    "## Serialization to disk and reading from disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d41350b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc.to_disk('my_doc.spacy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12cc85ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.tokens import Doc\n",
    "from spacy.vocab import Vocab\n",
    "my_vocab = Vocab() # create empty vocabulary or use existing compatible one, e.g. `nlp.vocab`\n",
    "loaded_doc = Doc(my_vocab).from_disk('my_doc.spacy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90e3d1ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_doc.to_json()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9941d6ed",
   "metadata": {},
   "source": [
    "## Combining a list of docs\n",
    "If you want to combine several docs in one document, you can use the static method (a function that is directly called from the class) `from_docs()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e08d9ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc2 = nlp('Mr. Smith continues to work for the company for the next 10 years.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a38aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_docs = Doc(nlp.vocab).from_docs([doc,doc2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b80a1bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_docs.to_json()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63909324",
   "metadata": {},
   "source": [
    "## Navigating the dependency structure\n",
    "Apart from following the head attribute of each token, there is more functionality for traversing the dependency relations.\n",
    "The [children](https://spacy.io/api/token#children) generator for immediatly dependent words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f1a78de",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc[2].children"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42766b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Head:\", doc[2])\n",
    "for c in doc[2].children:\n",
    "    print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62ac0f98",
   "metadata": {},
   "source": [
    "Navigating the dependency structure: enumerating the heads of a token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da5e1fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in doc[0].ancestors:\n",
    "    print(t, type(t))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ad65dc6",
   "metadata": {},
   "source": [
    "## Matching using token patterns\n",
    "spaCy has a powerful token-based pattern matching engine that can use [any of the linguistic properties of tokens for searching and adding informations](https://spacy.io/usage/rule-based-matching#adding-patterns-attributes). See the online demo for [interactively creating matching patterns](https://explosion.ai/demos/matcher).\n",
    "\n",
    "Let's implement a simple matcher:\n",
    "The normal NER of this model does not include titles. We can write a token matcher to rectify the situation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e1d7db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "displacy.render(doc2, style='ent',jupyter=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b2d832d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.matcher import Matcher\n",
    "matcher = Matcher(nlp.vocab) # initialize the matcher with the current Vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "063f0ca2",
   "metadata": {},
   "source": [
    "A pattern is a list of dictionaries. Each dictionary specifies a token pattern that can include regex-like repetition information. An empty dictionary `{}` matches any token. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39634f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = [{\"LOWER\":\"mr.\"},{\"ENT_TYPE\":\"PERSON\", \"OP\":\"+\"}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56b3fd78",
   "metadata": {},
   "outputs": [],
   "source": [
    "matcher.add(\"TitledPERSON\",[pattern])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af4228f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "matches = matcher(doc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e96d720",
   "metadata": {},
   "outputs": [],
   "source": [
    "for match_id, start, end in matches:\n",
    "    string_id = nlp.vocab.strings[match_id]          # Get string representation\n",
    "    span = doc[start:end]                            # The matched span\n",
    "    print(match_id, string_id, start, end, span.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8220a0a1",
   "metadata": {},
   "source": [
    "## Matching using Dependency Patterns\n",
    "We can match non-contiguous slices via dependency relations.\n",
    "See [usage guide](https://spacy.io/usage/rule-based-matching#dependencymatcher-patterns) for more information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b421878",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.matcher import DependencyMatcher\n",
    "dep_matcher = DependencyMatcher(nlp.vocab) # initialize the matcher with the current Vocab\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f49a14d5",
   "metadata": {},
   "source": [
    "Let's define a simple verb subject pattern!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "158ff99f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dep_pattern = [\n",
    "    {\n",
    "        \"RIGHT_ID\": \"anchor_founded\",      # Introduce ID for anchor token\n",
    "        \"RIGHT_ATTRS\": {\"ORTH\": \"founded\"} # Specify anchor token\n",
    "    },\n",
    "    {\n",
    "        \"LEFT_ID\": \"anchor_founded\",       # Refer to anchor token by its ID\n",
    "        \"REL_OP\": \">\",                     # Direct dependency\n",
    "        \"RIGHT_ID\": \"founded_subject\",     # Introduce ID for dependent subject \n",
    "        \"RIGHT_ATTRS\": {\"DEP\": \"nsubj\"},   # Specify subject token\n",
    "    } \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d731fd51",
   "metadata": {},
   "outputs": [],
   "source": [
    "dep_matcher.add(\"FOUNDED\", [dep_pattern])\n",
    "doc3 = nlp(\"Smith, an experienced CEO, has founded two AI startups.\")\n",
    "dep_matches = dep_matcher(doc3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f90c370f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dep_matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d96f32b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each token_id corresponds to one pattern dict\n",
    "match_id, token_ids = dep_matches[0]\n",
    "\n",
    "for i in range(len(token_ids)):\n",
    "    print(dep_pattern[i][\"RIGHT_ID\"] + \":\", doc3[token_ids[i]].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f24868",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc3 = nlp(\"Smith, an experienced CEO, has founded two AI startups. He also founded several other companies.\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
