{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Tokenizer for German Texts\n",
    "Learning goals:\n",
    " - Understand how a regex-based tokenizer works\n",
    " - Understand how a regex tokenizer can be adapted to text types with different properties and conventions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "pattern = r'''(?x)           # set flag (?x) to allow verbose regexps\n",
    "     (?:z\\.B\\.|bzw\\.|usw\\.)  # known abbreviations ...\n",
    "   | (?:\\w\\.)+               # abbreviations, e.g. U.S.A. or ordinals\n",
    "   | \\$?\\d+(?:[.,‘]\\d+)*[%€]? # currency/percentages, $12.40, 82% 23€\n",
    "   | \\w+(?:['-]\\w+)*         # words with optional internal hyphens or apostrophs\n",
    "   | (?:\\.\\.\\.|---?)         # ellipsis, ASCII long hyphens\n",
    "   | [.,;?!'–-—\\[\\]()]       # single character punctuation\n",
    "   | \\S+                     # catch-all for non-layout characters\n",
    "   '''\n",
    "\n",
    "def tokenize_line(string, pattern):\n",
    "    \"\"\"Return list of tokens according to a tokenization pattern\"\"\"\n",
    "    return re.findall(pattern, string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rawtext corpora from Gutenberg Project sometimes have ASCII markdown for formatting (e.g. `_`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_text = \"\"\"_Zweiter Streich._\n",
    "\n",
    "Als die gute Witwe Bolte\n",
    "Sich von ihrem Schmerz erholte,\n",
    "Dachte sie so hin und her,\n",
    "Daß es wohl das beste wär',\n",
    "Die Verstorb'nen, die hienieden\n",
    "Schon so frühe abgeschieden,\n",
    "Ganz im stillen und in Ehren\n",
    "Gut gebraten zu verzehren. --\n",
    "-- Freilich war die Trauer groß,\n",
    "Als sie nun so nackt und bloß\n",
    "Abgerupft am Herde lagen,\n",
    "Sie, die einst in schönen Tagen\n",
    "Bald im Hofe, bald im Garten\n",
    "Lebensfroh im Sande scharrten. --\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in tokenize_line(max_text, pattern): \n",
    "    print(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How can we fix the `_`? Try to modify the pattern above. If you cannot solve it, peek at the bottom of this notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "other_text = \"\"\"Das Staatssekretariat für Migration (SEM) bestätigt diese Angaben nicht.\n",
    "Sprecherin Léa Wertheimer sagt: «Die Lage ist volatil und kurzfristig\n",
    "sind verschiedene Entwicklungen möglich, was exakte Prognosen\n",
    "verunmöglicht.» Sie hält fest: «Eine Hochrechnung der Eintritte\n",
    "einzelner Tage auf einen Monat oder ein Quartal ist nicht seriös.» Zum\n",
    "jetzigen Zeitpunkt sei lediglich klar, dass die ursprüngliche Prognose\n",
    "von 29‘000 Asylgesuchen «deutlich übertroffen» wird. Das SEM korrigierte\n",
    "den Wert bereits vor Wochenfrist nach oben – auf 32‘000 bis 34‘000\n",
    "erwartete Gesuche.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in tokenize_line(other_text, pattern): \n",
    "    print(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can you improve the pattern of the tokenizer to work better on `other_text`?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fix for the _? \n",
    " - either preprocess before tokenization...\n",
    " - add as first regex `_ | # strictly one symbol token character`\n",
    " - or only split at the begin of a word..."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
