{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "ca5c907b-9c42-4ee7-87bf-aa90a7b5d936"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# NLTK vs. spaCy: Introduction to basic NLP Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "61f68eeb-4c5c-4e73-bd4a-8e50c65d6a90"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Learning goals:\n",
    " - Understand simple NLP pipline functionality for English in NLTK\n",
    " - See how a more modern and multilingual \"industrial strength\" framework works (SpaCy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('averaged_perceptron_tagger_eng')\n",
    "nltk.download('maxent_ne_chunker_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"At eight o'clock on Thursday morning \n",
    "Arthur didn't feel very good.\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "a113865b-aef8-4364-a8d6-08e5d05b03c7"
    }
   },
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = nltk.word_tokenize(text)\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "38031147-e67b-4460-b631-6bd0314d5e45"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## POS Tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagged = nltk.pos_tag(tokens)\n",
    "print(tagged)\n",
    "for t in tagged:\n",
    "    print(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "7bdc297e-bb08-4a33-88f5-ec85c39864cf"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Named Entity Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entities = nltk.chunk.ne_chunk(tagged)\n",
    "print(entities)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "f2cc0d70-a1e2-48b5-a34f-0879954fe4a1"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Stemming\n",
    "Create tab-delimited output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = nltk.stem.PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tok in nltk.word_tokenize('He believes in stemming.'):\n",
    "    print(tok, stemmer.stem(tok), sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " lemmatizer = nltk.stem.WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tok in nltk.word_tokenize('He believes in stemming.'):\n",
    "    print(tok, lemmatizer.lemmatize(tok), sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Your turn... Look at how it is done in spacy\n",
    "https://spacy.io contains descriptions of the small efficient model for English https://spacy.io/models/en#en_core_web_sm and the larger model https://spacy.io/models/en#en_core_web_trf. \n",
    "\n",
    "Do you notice a performance differenct?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only run this once (and maybe restart the kernel)\n",
    "! pip install spacy\n",
    "! python -m spacy download en_core_web_sm\n",
    "# You can also test a more accurate transformer-based spaCy pipeline (450MB of data)\n",
    "! python -m spacy download en_core_web_trf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "modelname = \"en_core_web_sm\"\n",
    "# modelname = \"en_core_web_trf\"\n",
    "# Load English tokenizer, tagger, parser, NER and word vectors\n",
    "nlp = spacy.load(modelname)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process whole documents\n",
    "text = (\"When Sebastian Thrun started working on self-driving cars at \"\n",
    "        \"Google in 2007, few people outside of the company took him \"\n",
    "        \"seriously. “I can tell you very senior CEOs of major American \"\n",
    "        \"car companies would shake my hand and turn away because I wasn’t \"\n",
    "        \"worth talking to,” said Thrun, in an interview with Recode earlier \"\n",
    "        \"this week.\")\n",
    "doc = nlp(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze syntax\n",
    "print(\"Noun phrases:\", [chunk.text for chunk in doc.noun_chunks])\n",
    "print(\"Verbs:\", [token.lemma_ for token in doc if token.pos_ == \"VERB\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find named entities, phrases and concepts\n",
    "for entity in doc.ents:\n",
    "    print(f\"{entity.text:20} {entity.label_:8} # {spacy.explain(entity.label_)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
