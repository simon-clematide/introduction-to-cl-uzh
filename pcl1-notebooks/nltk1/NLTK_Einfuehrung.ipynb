{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "ca5c907b-9c42-4ee7-87bf-aa90a7b5d936"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# NLTK vs. spaCy: Introduction to basic NLP Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "61f68eeb-4c5c-4e73-bd4a-8e50c65d6a90"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Learning goals:\n",
    " - Understand simple NLP pipline functionality for English in NLTK\n",
    " - See how a more modern and multilingual \"industrial strength\" framework works (SpaCy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]     /Users/siclemat/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package maxent_ne_chunker_tab to\n",
      "[nltk_data]     /Users/siclemat/nltk_data...\n",
      "[nltk_data]   Package maxent_ne_chunker_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('averaged_perceptron_tagger_eng')\n",
    "nltk.download('maxent_ne_chunker_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"At eight o'clock on Thursday morning \n",
    "Arthur didn't feel very good.\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "a113865b-aef8-4364-a8d6-08e5d05b03c7"
    }
   },
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['At', 'eight', \"o'clock\", 'on', 'Thursday', 'morning', 'Arthur', 'did', \"n't\", 'feel', 'very', 'good', '.']\n"
     ]
    }
   ],
   "source": [
    "tokens = nltk.word_tokenize(text)\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "38031147-e67b-4460-b631-6bd0314d5e45"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## POS Tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('At', 'IN'), ('eight', 'CD'), (\"o'clock\", 'NN'), ('on', 'IN'), ('Thursday', 'NNP'), ('morning', 'NN'), ('Arthur', 'NNP'), ('did', 'VBD'), (\"n't\", 'RB'), ('feel', 'VB'), ('very', 'RB'), ('good', 'JJ'), ('.', '.')]\n",
      "('At', 'IN')\n",
      "('eight', 'CD')\n",
      "(\"o'clock\", 'NN')\n",
      "('on', 'IN')\n",
      "('Thursday', 'NNP')\n",
      "('morning', 'NN')\n",
      "('Arthur', 'NNP')\n",
      "('did', 'VBD')\n",
      "(\"n't\", 'RB')\n",
      "('feel', 'VB')\n",
      "('very', 'RB')\n",
      "('good', 'JJ')\n",
      "('.', '.')\n"
     ]
    }
   ],
   "source": [
    "tagged = nltk.pos_tag(tokens)\n",
    "print(tagged)\n",
    "for t in tagged:\n",
    "    print(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "7bdc297e-bb08-4a33-88f5-ec85c39864cf"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Named Entity Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  At/IN\n",
      "  eight/CD\n",
      "  o'clock/NN\n",
      "  on/IN\n",
      "  Thursday/NNP\n",
      "  morning/NN\n",
      "  (PERSON Arthur/NNP)\n",
      "  did/VBD\n",
      "  n't/RB\n",
      "  feel/VB\n",
      "  very/RB\n",
      "  good/JJ\n",
      "  ./.)\n"
     ]
    }
   ],
   "source": [
    "entities = nltk.chunk.ne_chunk(tagged)\n",
    "print(entities)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "f2cc0d70-a1e2-48b5-a34f-0879954fe4a1"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Stemming\n",
    "Create tab-delimited output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = nltk.stem.PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "He\the\n",
      "believes\tbeliev\n",
      "in\tin\n",
      "stemming\tstem\n",
      ".\t.\n"
     ]
    }
   ],
   "source": [
    "for tok in nltk.word_tokenize('He believes in stemming.'):\n",
    "    print(tok, stemmer.stem(tok), sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    " lemmatizer = nltk.stem.WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "He\tHe\n",
      "believes\tbelief\n",
      "in\tin\n",
      "stemming\tstemming\n",
      ".\t.\n"
     ]
    }
   ],
   "source": [
    "for tok in nltk.word_tokenize('He believes in stemming.'):\n",
    "    print(tok, lemmatizer.lemmatize(tok), sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Your turn... Look at how it is done in spacy\n",
    "https://spacy.io contains descriptions of the small efficient model for English https://spacy.io/models/en#en_core_web_sm and the larger model https://spacy.io/models/en#en_core_web_trf. \n",
    "\n",
    "Do you notice a performance differenct?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spacy in /Users/siclemat/lehre/hs25/pcl1/introduction-to-cl-uzh/venv/lib/python3.11/site-packages (3.8.8)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /Users/siclemat/lehre/hs25/pcl1/introduction-to-cl-uzh/venv/lib/python3.11/site-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /Users/siclemat/lehre/hs25/pcl1/introduction-to-cl-uzh/venv/lib/python3.11/site-packages (from spacy) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /Users/siclemat/lehre/hs25/pcl1/introduction-to-cl-uzh/venv/lib/python3.11/site-packages (from spacy) (1.0.14)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /Users/siclemat/lehre/hs25/pcl1/introduction-to-cl-uzh/venv/lib/python3.11/site-packages (from spacy) (2.0.12)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /Users/siclemat/lehre/hs25/pcl1/introduction-to-cl-uzh/venv/lib/python3.11/site-packages (from spacy) (3.0.11)\n",
      "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in /Users/siclemat/lehre/hs25/pcl1/introduction-to-cl-uzh/venv/lib/python3.11/site-packages (from spacy) (8.3.8)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /Users/siclemat/lehre/hs25/pcl1/introduction-to-cl-uzh/venv/lib/python3.11/site-packages (from spacy) (1.1.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /Users/siclemat/lehre/hs25/pcl1/introduction-to-cl-uzh/venv/lib/python3.11/site-packages (from spacy) (2.5.1)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /Users/siclemat/lehre/hs25/pcl1/introduction-to-cl-uzh/venv/lib/python3.11/site-packages (from spacy) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.4.2 in /Users/siclemat/lehre/hs25/pcl1/introduction-to-cl-uzh/venv/lib/python3.11/site-packages (from spacy) (0.4.2)\n",
      "Requirement already satisfied: typer-slim<1.0.0,>=0.3.0 in /Users/siclemat/lehre/hs25/pcl1/introduction-to-cl-uzh/venv/lib/python3.11/site-packages (from spacy) (0.20.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /Users/siclemat/lehre/hs25/pcl1/introduction-to-cl-uzh/venv/lib/python3.11/site-packages (from spacy) (4.67.1)\n",
      "Requirement already satisfied: numpy>=1.19.0 in /Users/siclemat/lehre/hs25/pcl1/introduction-to-cl-uzh/venv/lib/python3.11/site-packages (from spacy) (1.26.4)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /Users/siclemat/lehre/hs25/pcl1/introduction-to-cl-uzh/venv/lib/python3.11/site-packages (from spacy) (2.32.5)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /Users/siclemat/lehre/hs25/pcl1/introduction-to-cl-uzh/venv/lib/python3.11/site-packages (from spacy) (2.12.4)\n",
      "Requirement already satisfied: jinja2 in /Users/siclemat/lehre/hs25/pcl1/introduction-to-cl-uzh/venv/lib/python3.11/site-packages (from spacy) (3.1.6)\n",
      "Requirement already satisfied: setuptools in /Users/siclemat/lehre/hs25/pcl1/introduction-to-cl-uzh/venv/lib/python3.11/site-packages (from spacy) (80.9.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/siclemat/lehre/hs25/pcl1/introduction-to-cl-uzh/venv/lib/python3.11/site-packages (from spacy) (25.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/siclemat/lehre/hs25/pcl1/introduction-to-cl-uzh/venv/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in /Users/siclemat/lehre/hs25/pcl1/introduction-to-cl-uzh/venv/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.41.5)\n",
      "Requirement already satisfied: typing-extensions>=4.14.1 in /Users/siclemat/lehre/hs25/pcl1/introduction-to-cl-uzh/venv/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.15.0)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in /Users/siclemat/lehre/hs25/pcl1/introduction-to-cl-uzh/venv/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.4.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/siclemat/lehre/hs25/pcl1/introduction-to-cl-uzh/venv/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/siclemat/lehre/hs25/pcl1/introduction-to-cl-uzh/venv/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/siclemat/lehre/hs25/pcl1/introduction-to-cl-uzh/venv/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/siclemat/lehre/hs25/pcl1/introduction-to-cl-uzh/venv/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2025.10.5)\n",
      "Requirement already satisfied: blis<1.4.0,>=1.3.0 in /Users/siclemat/lehre/hs25/pcl1/introduction-to-cl-uzh/venv/lib/python3.11/site-packages (from thinc<8.4.0,>=8.3.4->spacy) (1.3.2)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /Users/siclemat/lehre/hs25/pcl1/introduction-to-cl-uzh/venv/lib/python3.11/site-packages (from thinc<8.4.0,>=8.3.4->spacy) (0.1.5)\n",
      "Requirement already satisfied: click>=8.0.0 in /Users/siclemat/lehre/hs25/pcl1/introduction-to-cl-uzh/venv/lib/python3.11/site-packages (from typer-slim<1.0.0,>=0.3.0->spacy) (8.3.0)\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /Users/siclemat/lehre/hs25/pcl1/introduction-to-cl-uzh/venv/lib/python3.11/site-packages (from weasel<0.5.0,>=0.4.2->spacy) (0.23.0)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /Users/siclemat/lehre/hs25/pcl1/introduction-to-cl-uzh/venv/lib/python3.11/site-packages (from weasel<0.5.0,>=0.4.2->spacy) (7.5.0)\n",
      "Requirement already satisfied: wrapt in /Users/siclemat/lehre/hs25/pcl1/introduction-to-cl-uzh/venv/lib/python3.11/site-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.4.2->spacy) (2.0.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/siclemat/lehre/hs25/pcl1/introduction-to-cl-uzh/venv/lib/python3.11/site-packages (from jinja2->spacy) (3.0.3)\n",
      "Collecting en-core-web-sm==3.8.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m46.8 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\u001b[31m26.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n",
      "Collecting en-core-web-trf==3.8.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_trf-3.8.0/en_core_web_trf-3.8.0-py3-none-any.whl (457.4 MB)\n"
     ]
    }
   ],
   "source": [
    "# Only run this once (and maybe restart the kernel)\n",
    "! pip install spacy\n",
    "! python -m spacy download en_core_web_sm\n",
    "# You can also test a more accurate transformer-based spaCy pipeline (450MB of data)\n",
    "! python -m spacy download en_core_web_trf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "modelname = \"en_core_web_sm\"\n",
    "# modelname = \"en_core_web_trf\"\n",
    "# Load English tokenizer, tagger, parser, NER and word vectors\n",
    "nlp = spacy.load(modelname)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process whole documents\n",
    "text = (\"When Sebastian Thrun started working on self-driving cars at \"\n",
    "        \"Google in 2007, few people outside of the company took him \"\n",
    "        \"seriously. “I can tell you very senior CEOs of major American \"\n",
    "        \"car companies would shake my hand and turn away because I wasn’t \"\n",
    "        \"worth talking to,” said Thrun, in an interview with Recode earlier \"\n",
    "        \"this week.\")\n",
    "doc = nlp(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Noun phrases: ['Sebastian Thrun', 'self-driving cars', 'Google', 'few people', 'the company', 'him', 'I', 'you', 'very senior CEOs', 'major American car companies', 'my hand', 'I', 'Thrun', 'an interview', 'Recode']\n",
      "Verbs: ['start', 'work', 'drive', 'take', 'tell', 'shake', 'turn', 'talk', 'say']\n"
     ]
    }
   ],
   "source": [
    "# Analyze syntax\n",
    "print(\"Noun phrases:\", [chunk.text for chunk in doc.noun_chunks])\n",
    "print(\"Verbs:\", [token.lemma_ for token in doc if token.pos_ == \"VERB\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sebastian Thrun      PERSON   # People, including fictional\n",
      "Google               ORG      # Companies, agencies, institutions, etc.\n",
      "2007                 DATE     # Absolute or relative dates or periods\n",
      "American             NORP     # Nationalities or religious or political groups\n",
      "Thrun                PERSON   # People, including fictional\n",
      "Recode               ORG      # Companies, agencies, institutions, etc.\n",
      "earlier this week    DATE     # Absolute or relative dates or periods\n"
     ]
    }
   ],
   "source": [
    "# Find named entities, phrases and concepts\n",
    "for entity in doc.ents:\n",
    "    print(f\"{entity.text:20} {entity.label_:8} # {spacy.explain(entity.label_)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
