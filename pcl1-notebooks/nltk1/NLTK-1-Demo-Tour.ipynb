{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# NLTK 1: Interactive exploration of  corpora\n",
    "Learning goals:\n",
    " - Understand how useful raw text corpora can be\n",
    " - Understand what we can understand about language by quantitative and distributional corpus linguistic applications\n",
    " - Know how list comprehension helps to quickly do interactive exploration of corpora"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Loading the NLTK Interactive Demo\n",
    "This code is really meant for interactive exploration and prints out results more than returning values to compute with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.book import *\n",
    "texts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Texts are sequences of tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text1[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Create concordances\n",
    "KWIC (Keyword in Context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text1.concordance(\"man\", lines=10, width=68)\n",
    "print()\n",
    "text2.concordance(\"man\",lines=10, width=68)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "text1.concordance(\"woman\", lines=10, width=68)\n",
    "print()\n",
    "text2.concordance(\"woman\",lines=10, width=68)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Word frequencies in a corpus\n",
    "Let's compute relative frequencies..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text1.count('love')/len(text1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text2.count('love')/len(text2) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Frequency distributions\n",
    "Calculate the frequency of all different tokens (=Types) in a text. \n",
    "Should follow the [Zipfian Law](https://en.wikipedia.org/wiki/Zipf%27s_law) for larger text corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fdist = FreqDist(text1)\n",
    "vocabulary= sorted(fdist, key=fdist.get, reverse=True)\n",
    "for w in vocabulary[:20]:\n",
    "    print(w, \"\\t\\t\", fdist[w])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "<h3>Printing a plot</h3>\n",
    "Make sure that the plot object is rendered by Jupyter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline  \n",
    "fdist.plot(20,cumulative=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Similarity\n",
    "Distributional similarity \n",
    "- \"You shall know a word by the company it keeps!\" (J. R. Firth, 1957)\n",
    "- \"words that occur in the same contexts tend to have similar meanings\" (Pantel, 2005)\n",
    "\n",
    "Which words do appear in similar contexts?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text1.similar(\"woman\")\n",
    "print()\n",
    "text2.similar(\"woman\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "text1.similar(\"love\")\n",
    "print()\n",
    "text2.similar(\"love\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Statistical collocations\n",
    "Which words occur unexpectedly often next to each other?\n",
    " - Simple **expected frequency** of word grammars: Each word lies in an urn as often as it occurs in the corpus. Randomly draw two words one after the other from the urn.\n",
    " - Empirical frequency** of word bigrams: Create the probability distribution of all word bigrams effectively occurring in the corpus.\n",
    " - If expected frequency deviates strongly from empirical frequency, a [statistical collocation] (https://en.wikipedia.org/wiki/Collocation) is available.\n",
    " \n",
    "collocation method is currently buggy, use collocation_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(text1.collocation_list())\n",
    "print()\n",
    "print(text2.collocation_list())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Dispersion plots\n",
    "Where do words appear how often on a timeline? U.S. Inaugural Addresses\n",
    " - Timeline is implicit in the chronological order of the speeches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text4.dispersion_plot([\"freedom\",\"war\"])\n",
    "text4.dispersion_plot([\"economy\",\"war\",\"digital\",\"slavery\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Text generation\n",
    "Do you have to make a political speech? Let yourself be inspired by the presidential speeches of the past presidents of the USA. \n",
    " - Statistical generation of texts e.g. from trigram statistics of words. Typical word combinations from a corpus are used to build a probability distribution for the next word to generate. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = text4.generate(text_seed=\"Freedom\".split(),length=40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sophisticated text generation using recursive neural networks, which can take a little more of the already expressed material into account when proposing the next word: https://cyborg.tenso.rs\n",
    " - Recommended: Language model of (re-)tweets by/with Donald Trump (e.g. start with \"America\")\n",
    " - Start with \"I love\" and select different training corpora (e.g. Linux:-)\n",
    "\n",
    "Transformer-based text generation, which is the best method currently:\n",
    " - [Automatic Text Generation is](https://transformer.huggingface.co/doc/arxiv-nlp/SBXtFhUnmNIAtyDMpRNGxuIl/edit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# List comprehension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Vocabulary = set(text2)\n",
    "long_words = [w for w in Vocabulary if len(w)>15]\n",
    "long_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(set)"
   ]
  }
 ],
 "metadata": {
  "livereveal": {
   "center": false,
   "embedded": false,
   "scroll": true,
   "start_slideshow_at": "selected",
   "theme": "simple",
   "transition": "fade"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
